[program:main]
# user = nobody
;启动命令
; stop uwsgi : ps -ef | grep uwsgi | grep -v grep | awk '{print $2}'  | xargs kill -9
;command = uwsgi --ini uwsgi.ini
command = python manage.py runserver 0.0.0.0:8001

;程序的启动目录
directory = /code/
autostart = true
autorestart = true
redirect_stderr = true
stdout_logfile = /code/logs/super_main.log
stderr_logfile = /code/logs/super_main_error.log
stdout_logfile_maxbytes = 50MB
stdout_logfile_backups = 3

startsecs = 10

; Need to wait for currently executing tasks to finish at shutdown.
; Increase this if you have very long running tasks.
stopwaitsecs = 600

; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
stopasgroup = true

; if rabbitmq is supervised, set its priority higher
; so it starts first
priority = 1000


[program:nginx]
command = nginx -g "daemon off;"
autostart = true
autorestart = true
redirect_stderr = true
stdout_logfile = /code/logs/nginx.log
stderr_logfile = /code/logs/nginx_error.log
stdout_logfile_maxbytes = 50MB
stdout_logfile_backups = 3
startsecs = 5
stopwaitsecs = 30
priority = 999


;[program:celery_work]
;;celery supervisord worker config
;;https://github.com/celery/celery/blob/main/extra/supervisord/celeryd.conf
;
;user = root
;;启动命令
;;https://docs.celeryq.dev/en/stable/userguide/workers.html#starting-the-worker
;;windows --pool=solo
;;command = celery multi start w3 -A bkm worker -l INFO  -n worker.%%h
;;command = celery multi restart w3 -A bkm worker -l INFO  -n worker.%%h
;;command = celery multi stopwait w3 -A bkm worker -l INFO  -n worker.%%h
;; Alternatively,
;;command=celery --app=your_app.celery:app worker --loglevel=INFO -n worker.%%h
;; Or run a script
;;command=celery.sh
;command = celery -A ProjectManage worker -l INFO  -n worker.%%h
;
;;程序的启动目录
;directory = /code/
;autostart = true
;autorestart = true
;redirect_stderr = true
;stdout_logfile = /code/logs/celery_work.log
;stderr_logfile = /code/logs/celery_work_error.log
;stdout_logfile_maxbytes = 50MB
;stdout_logfile_backups = 5
;
;startsecs = 10
;
;; Need to wait for currently executing tasks to finish at shutdown.
;; Increase this if you have very long running tasks.
;stopwaitsecs = 600
;
;; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
;stopasgroup = true
;
;; if rabbitmq is supervised, set its priority higher
;; so it starts first
;priority = 1000
;
;
;[program:celery_beat]
;;celery supervisord beat config
;;https://github.com/celery/celery/blob/main/extra/supervisord/celerybeat.conf
;
;user = root
;;启动命令
;; Set full path to celery program if using virtualenv
;;command=celery -A myapp beat --schedule /var/lib/celery/beat.db --loglevel=INFO
;; remove the -A myapp argument if you aren't using an app instance
;command = celery -A ProjectManage beat -l INFO
;
;;程序的启动目录
;directory = /code/
;autostart = true
;autorestart = true
;redirect_stderr = true
;stdout_logfile = /code/logs/celery_beat.log
;stderr_logfile = /code/logs/celery_beat_error.log
;stdout_logfile_maxbytes = 10MB
;stdout_logfile_backups = 5
;
;startsecs = 10
;
;; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
;stopasgroup = true
;
;; if rabbitmq is supervised, set its priority higher
;; so it starts first
;priority = 999


;[program:ws_main]
;user = nobody
;;启动命令
;; stop uwsgi : ps -ef | grep uwsgi | grep -v grep | awk '{print $2}'  | xargs kill -9
;;command = uwsgi --ini uwsgi.ini
;command = python main_uvicorn.py
;
;;程序的启动目录
;directory = /code/
;autostart = true
;autorestart = true
;redirect_stderr = true
;stdout_logfile = /code/logs/super_ws_main.log
;stderr_logfile = /code/logs/super_ws_main_error.log
;stdout_logfile_maxbytes = 50MB
;stdout_logfile_backups = 3
;
;startsecs = 10
;
;; Need to wait for currently executing tasks to finish at shutdown.
;; Increase this if you have very long running tasks.
;stopwaitsecs = 600
;
;; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
;stopasgroup = true
;
;; if rabbitmq is supervised, set its priority higher
;; so it starts first
;priority = 1000


;[fcgi-program:ws_asgi]
;;https://channels.readthedocs.io/en/stable/deploying.html
;user = nobody
;
;# TCP socket used by Nginx backend upstream
;socket = tcp://0.0.0.0:8000
;
;# Directory where your site's project files are located
;directory = /code
;
;# Each process needs to have a separate socket file, so we use process_num
;# Make sure to update "mysite.asgi" to match your project name
;command = daphne -u /run/daphne/daphne%(process_num)d.sock --fd 0 --access-log - --proxy-headers bkm.asgi:application
;
;# Number of processes to startup, roughly the number of CPUs you have
;;numprocs = 4
;
;# Give each process a unique name so they can be told apart
;process_name = asgi%(process_num)d
;
;# Automatically start and recover processes
;autostart = true
;autorestart = true
;
;# Choose where you want your log to go
;stdout_logfile = /code/logs/bkm_asgi.log
;stderr_logfile = /code/logs/bkm_asgi_error.log
;stdout_logfile_maxbytes = 50MB
;stdout_logfile_backups = 5
;redirect_stderr = true
;
;
;startsecs = 10
;
;; Need to wait for currently executing tasks to finish at shutdown.
;; Increase this if you have very long running tasks.
;stopwaitsecs = 600
;
;; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
;stopasgroup = true
;
;; if rabbitmq is supervised, set its priority higher
;; so it starts first
;priority = 1000


;[program:flower]
;if you need celery flower monitor
;please pip install flower
;user = nobody
;
;;程序的启动目录
;directory = /code/
;autostart = true
;autorestart = true
;redirect_stderr = true
;
;command = celery -A bkm flower --conf=./bkm/flower.py
;
;stdout_logfile = /code/logs/celery_flower.log
;stderr_logfile = /code/logs/celery_flower_error.log
;stdout_logfile_maxbytes = 50MB
;stdout_logfile_backups = 5
;
;startsecs = 10
;
;; Causes supervisor to send the termination signal (SIGTERM) to the whole process group.
;stopasgroup = true
;
;; if rabbitmq is supervised, set its priority higher
;; so it starts first
;priority = 999
